{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388f4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tfrecord_excav\n",
    "import pca_plot\n",
    "import pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a8d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr2D = np.load('X_reduced_2_5k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c39a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[214, 232, 187, 61, 91, 149, 80, 18, 136, 26, 37, 239, 97, 22, 171, 91, 74, 21, 132, 223, 90, 141, 223, 96, 221, 213, 191, 167, 65, 20, 146, 120, 62, 179, 71, 229, 229, 175, 177, 64, 27, 62, 211, 69, 190, 187, 180, 180, 127, 37, 90, 121, 19, 173, 35, 195, 79, 124, 197, 176, 215, 74, 77, 113, 21, 227, 111, 181, 167, 144, 226, 21, 238, 99, 213, 182, 161, 217, 14, 229, 138, 68, 79, 136, 139, 62, 164, 128, 39, 228, 75, 148, 114, 244, 35, 234, 212, 140, 174, 36, 21, 227, 92, 163, 77, 127, 143, 91, 236, 220, 163, 38, 176, 117, 20, 236, 16, 121, 71, 88, 239, 64, 243, 216, 223, 165, 22, 142, 147, 162, 70, 236, 43, 143, 31, 12, 79, 149, 178, 79, 188, 175, 41, 226, 129, 16, 228, 14, 198, 166, 221, 120, 127, 236, 171, 211, 140, 214, 23, 82, 29, 190, 95, 236, 191, 167, 216, 238, 133, 132, 121, 223, 111, 244, 66, 184, 196, 229, 169, 186, 122, 125, 177, 185, 134, 14, 228, 236]\n",
      "[83, 235, 73, 93, 145, 47, 40]\n",
      "[218, 218, 46, 170, 219, 137, 119, 248, 84]\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "./learning_to_simulate/datasets/Excavation_PCA/train.tfrecord; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cadb01d8f3de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mtfr_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{split}.tfrecord'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfr_filename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mlen_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/lib/io/tf_record.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, options)\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m       self._writer = pywrap_tensorflow.PyRecordWriter_New(\n\u001b[0;32m--> 218\u001b[0;31m           compat.as_bytes(path), options._as_record_writer_options(), status)\n\u001b[0m\u001b[1;32m    219\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    557\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ./learning_to_simulate/datasets/Excavation_PCA/train.tfrecord; No such file or directory"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Example usage (from parent directory):\n",
    "`python -m subspace_data.run_tfrecord_excav_pca`\n",
    "\n",
    "'''\n",
    "\n",
    "# import pickle\n",
    "\n",
    "\n",
    "\n",
    "MODE_NUMBER = 8\n",
    "VISUALIZATION = False\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset_load = './learning_to_simulate/datasets/' + 'Excavation'\n",
    "    dataset_save = dataset_load + '_PCA'\n",
    "\n",
    "\n",
    "    # Shuffle and create train, valid, and test examples (cases)\n",
    "    no_examples = 5*5*5*2  # 250\n",
    "    no_train_examples = int(0.90 * no_examples)  # to train model\n",
    "    no_valid_examples = int(0.05 * no_examples)  # to tune hyperparameters  \n",
    "    no_test_examples  = int(0.05 * no_examples)  # to evaluate final model\n",
    "\n",
    "    example_list = list(range(1, 1 + no_examples))\n",
    "    random.shuffle(example_list)\n",
    "    train_example_list = random.choices(example_list, k=no_train_examples)\n",
    "    example_list = [ elem for elem in example_list if elem not in train_example_list]\n",
    "    valid_example_list = random.choices(example_list, k=no_valid_examples)\n",
    "    example_list = [ elem for elem in example_list if elem not in valid_example_list]\n",
    "    test_example_list = random.choices(example_list, k=no_test_examples)\n",
    "\n",
    "    # train_example_list = [240]\n",
    "    dataset_split = {\n",
    "        'train': train_example_list,\n",
    "        'valid': valid_example_list,\n",
    "        'test': test_example_list\n",
    "    }\n",
    "\n",
    "    # Exclude bad examples (cases)\n",
    "    for split in dataset_split:\n",
    "        c1 = 0\n",
    "        for depth in [0.02, 0.04, 0.05, 0.08, 0.1]:\n",
    "            for speed in [0.01, 0.04, 0.08, 0.1, 0.15]:\n",
    "                for angle in [0.0, 3.8, 10.0, 30.8, 45.0]:\n",
    "                    for motion in [1.0, 2.0]:\n",
    "                        c1 += 1\n",
    "                        if speed == 0.01:  \n",
    "                            dataset_split[split] = [ elem for elem in dataset_split[split] if elem != c1]\n",
    "        print(dataset_split[split])\n",
    "\n",
    "\n",
    "    # # Load PCA loading matrix and mean scalar\n",
    "    # with open(dataset_save + '/' + 'pca_eigen_vectors.pkl', 'rb') as f:\n",
    "    #     W = pickle.load(f)\n",
    "    #     W = W[:, :MODE_NUMBER]\n",
    "    # with open(dataset_save + '/' + 'pca_mean_scalar.pkl', 'rb') as f:\n",
    "    #     MEAN = pickle.load(f)\n",
    "\n",
    "\n",
    "    # Simulation properties\n",
    "    scale_dim = 0.25  # If dimensional analysis used\n",
    "    scale_time = scale_dim * 2\n",
    "    scale_vel = scale_dim * 2\n",
    "    frame_rate = 120 * scale_time\n",
    "    dimension = 3\n",
    "    bounds = [[0.1, 0.9],\n",
    "              [0.2, 1.0],\n",
    "              [0.1, 0.9]]\n",
    "    plate_height = 0.0763/scale_dim\n",
    "    plate_width = 0.1142/scale_dim\n",
    "\n",
    "\n",
    "    # Start\n",
    "    for counter, split in enumerate(dataset_split):\n",
    "        # Initialization \n",
    "        particle_key = 0\n",
    "        c2, c3, frames = 0, 0, 0\n",
    "        if split == 'train':   \n",
    "            particle_vel_mean, particle_vel_var = [0., 0., 0.], [0., 0., 0.]\n",
    "            particle_acc_mean, particle_acc_var = [0., 0., 0.], [0., 0., 0.]\n",
    "            rigid_body_force_mean, rigid_body_force_var = [0., 0., 0.], [0., 0., 0.]\n",
    "            n1_v, n2_v = 0, 0\n",
    "            n1_a, n2_a = 0, 0\n",
    "            n1_f, n2_f = 0, 0\n",
    "\n",
    "        tfr_filename = os.path.join(dataset_save, f'{split}.tfrecord')\n",
    "        with tf.python_io.TFRecordWriter(tfr_filename) as writer:\n",
    "            \n",
    "            len_split = len(dataset_split[split])\n",
    "            while c2 < len_split:\n",
    "\n",
    "                c1 = 0\n",
    "                for depth in [0.02, 0.04, 0.05, 0.08, 0.1]:\n",
    "                    for speed in [0.01, 0.04, 0.08, 0.1, 0.15]:\n",
    "                        for angle in [0.0, 3.8, 10.0, 30.8, 45.0]:\n",
    "                            for motion in [1.0, 2.0]:\n",
    "                                c1 += 1\n",
    "\n",
    "                                if dataset_split[split][c3] == c1:\n",
    "\n",
    "                                    task_id = str(c1) + '_D' + str(depth) + 'm_S' + str(\n",
    "                                        speed) + 'ms-1_A' + str(angle) + 'deg_M' + str(motion)\n",
    "\n",
    "                                    ds_path_load = os.path.join(dataset_load, task_id)\n",
    "                                    if VISUALIZATION:\n",
    "                                        ds_path_save = os.path.join(dataset_save, task_id)\n",
    "                                        if not os.path.exists(ds_path_save):\n",
    "                                            os.makedirs(ds_path_save)\n",
    "\n",
    "                                    path, dirs, files = next(os.walk(os.path.join(ds_path_load, 'frames')))\n",
    "                                    frames = min(320, len(files)-1)\n",
    "\n",
    "                                    particle_id = []\n",
    "                                    particle_type = []\n",
    "                                    particle_pos = []\n",
    "                                    rigid_body_force = []\n",
    "                                    if VISUALIZATION:\n",
    "                                        particle_type_np = []\n",
    "                                        particle_pos_np = []\n",
    "                                    print(task_id)\n",
    "                                    for frame in range(1, frames+1):\n",
    "                                        r_particles = 0\n",
    "                                        particle_id_frame = []\n",
    "                                        particle_type_frame = []\n",
    "                                        particle_pos_frame = []\n",
    "                                        rigid_body_force_frame = []\n",
    "                                        r_particle_pos_x_min = 10\n",
    "                                        r_particle_pos_y_min = 10\n",
    "                                        r_particle_pos_z_min = 10\n",
    "                                        if VISUALIZATION:\n",
    "                                            particle_type_frame_np = []\n",
    "                                            particle_pos_frame_np = []\n",
    "\n",
    "                                        file_path = os.path.join(\n",
    "                                            ds_path_load, 'frames/ds_' + \"{0:0=4d}\".format(frame) + '.csv')\n",
    "\n",
    "                                        data_frame = tfrecord_excav.read_csv(file_path)\n",
    "                                        all_particles = len(data_frame)\n",
    "\n",
    "                                        # Get one particle in rigid body\n",
    "                                        for particle in reversed(range(1, all_particles)):\n",
    "                                            if int(data_frame['col0'][particle]) == 1:\n",
    "                                                minx = round(float(data_frame['col1'][particle])/scale_dim, 6)\n",
    "                                                miny = round(float(data_frame['col2'][particle])/scale_dim, 6)\n",
    "                                                minz = round(float(data_frame['col3'][particle])/scale_dim, 6)\n",
    "                                                if minx < r_particle_pos_x_min:\n",
    "                                                    r_particle_pos_x_min = minx\n",
    "                                                if miny < r_particle_pos_y_min:\n",
    "                                                    r_particle_pos_y_min = miny\n",
    "                                                if minz < r_particle_pos_z_min:\n",
    "                                                    r_particle_pos_z_min = minz\n",
    "                                        # Create structured rigid body\n",
    "                                        res = 10000\n",
    "                                        grid_size = int(res*0.10)  # [m]\n",
    "                                        for iz in range(int(r_particle_pos_z_min*res), int((r_particle_pos_z_min+plate_width)*res), grid_size):\n",
    "                                            for iy in range(int(r_particle_pos_y_min*res), int((r_particle_pos_y_min + plate_height*np.cos(np.deg2rad(angle)))*res), grid_size):\n",
    "                                                r_particles += 1\n",
    "                                                particle_id_frame.append(-1)\n",
    "                                                particle_pos_frame.append([\n",
    "                                                    r_particle_pos_x_min + np.tan(np.deg2rad(angle))*(iy/res-r_particle_pos_y_min),\n",
    "                                                    iy/res,\n",
    "                                                    iz/res])\n",
    "                                                # Particle type: soil: 6, boundary: 3, rigid: 0\n",
    "                                                particle_type_frame.append(3)\n",
    "                                                if VISUALIZATION:\n",
    "                                                    particle_pos_frame_np.append(np.array([\n",
    "                                                        r_particle_pos_x_min + np.tan(np.deg2rad(angle))*(iy/res-r_particle_pos_y_min),\n",
    "                                                        iy/res,\n",
    "                                                        iz/res]))\n",
    "                                                    particle_type_frame_np.append(np.array(3))\n",
    "\n",
    "                                        for particle in range(1, all_particles):\n",
    "                                            if ~np.isnan(float(data_frame['col1'][particle])):\n",
    "                                                if (int(data_frame['col0'][particle]) == 0) and (particle%5 == 0):\n",
    "                                                    particle_id_frame.append(particle)\n",
    "                                                    particle_pos_frame.append([\n",
    "                                                        round(float(data_frame['col1'][particle])/scale_dim, 6),\n",
    "                                                        round(float(data_frame['col2'][particle])/scale_dim, 6),\n",
    "                                                        round(float(data_frame['col3'][particle])/scale_dim, 6)])\n",
    "                                                    particle_type_frame.append(6)\n",
    "                                                    if VISUALIZATION:\n",
    "                                                        particle_pos_frame_np.append(np.array([\n",
    "                                                            round(float(data_frame['col1'][particle])/scale_dim, 6),\n",
    "                                                            round(float(data_frame['col2'][particle])/scale_dim, 6),\n",
    "                                                            round(float(data_frame['col3'][particle])/scale_dim, 6)]))\n",
    "                                                        particle_type_frame_np.append(np.array(6))\n",
    "                                            else:\n",
    "                                                particle_id_frame.append(particle)\n",
    "                                                particle_type_frame_np.append(np.array(6))\n",
    "                                                particle_pos_frame.append(particle_pos[frame-1][particle])\n",
    "\n",
    "                                        particle_id.append(particle_id_frame)\n",
    "                                        particle_type.append(particle_type_frame)\n",
    "                                        particle_pos.append(particle_pos_frame)\n",
    "                                        rigid_body_force.append([\n",
    "                                            round(float(data_frame['col0'][0])/(scale_dim**3), 6),\n",
    "                                            round(float(data_frame['col1'][0])/(scale_dim**3), 6),\n",
    "                                            round(float(data_frame['col2'][0])/(scale_dim**3), 6)])\n",
    "                                        if VISUALIZATION:\n",
    "                                            particle_type_np.append(np.array(particle_type_frame_np))\n",
    "                                            particle_pos_np.append(np.array(particle_pos_frame_np))\n",
    "                                        # Extra frame in the beginning\n",
    "                                        if frame == 1:\n",
    "                                            particle_id.append(particle_id_frame.copy())\n",
    "                                            particle_type.append(particle_type_frame.copy())\n",
    "                                            particle_pos.append(particle_pos_frame.copy())\n",
    "                                            rigid_body_force.append([\n",
    "                                                round(float(data_frame['col0'][0])/(scale_dim**3), 6),\n",
    "                                                round(float(data_frame['col1'][0])/(scale_dim**3), 6),\n",
    "                                                round(float(data_frame['col2'][0])/(scale_dim**3), 6)])\n",
    "                                            if VISUALIZATION:\n",
    "                                                particle_type_np.append(np.array(particle_type_frame_np))\n",
    "                                                particle_pos_np.append(np.array(particle_pos_frame_np))\n",
    "                                        if frame % 10 == 0:\n",
    "                                            print(c2+1, ':', round(frame/frames, 3)*100, '%')\n",
    "                                    del particle_pos_frame\n",
    "                                    del data_frame\n",
    "                                    particles = len(particle_pos[0])\n",
    "\n",
    "\n",
    "                                    ''' Process data '''\n",
    "                                    # print(r_particles)\n",
    "                                    # Convert 3D soil data to 2D data\n",
    "                                    # X = np.zeros((dimension*(frames+1), particles-r_particles))\n",
    "                                    # for i in range((frames+1)):\n",
    "                                    #     for j in range(r_particles, particles):\n",
    "                                    #         for k in range(dimension):\n",
    "                                    #             X[k+i*dimension][j-r_particles] = particle_pos[i][j][k] - MEAN\n",
    "\n",
    "                                    # Apply PCA to 2D data\n",
    "                                    #Xr2D = np.matmul(X, W)\n",
    "                                    Xr2D = np.load('X_reduced_2_5k.npy')\n",
    "                                    # Convert 2D data to 3D data\n",
    "                                    Xr = np.zeros((frames+1, MODE_NUMBER+r_particles, dimension))\n",
    "                                    for i in range(frames+1):\n",
    "                                        for j in range(r_particles):\n",
    "                                            for k in range(dimension):\n",
    "                                                Xr[i][j][k] = particle_pos[i][j][k]\n",
    "                                    for i in range(dimension*(frames+1)):\n",
    "                                        for j in range(MODE_NUMBER):\n",
    "                                            Xr[i // int(dimension)][j+r_particles][i % int(dimension)] = Xr2D[i][j]\n",
    "\n",
    "                                    if VISUALIZATION:\n",
    "                                        particle_type_np_r = np.ones(((frames+1), r_particles+MODE_NUMBER))*3\n",
    "                                        for i in range(frames+1):\n",
    "                                            for j in range(r_particles, r_particles+MODE_NUMBER):\n",
    "                                                particle_type_np_r[i][j] = particle_type_np[i][j]\n",
    "                                        pca_plot.plot(Xr, particle_type_np_r)\n",
    "                                        del particle_type_frame_np\n",
    "                                        del particle_pos_frame_np\n",
    "                                        del particle_pos_np\n",
    "                                        del particle_type_np\n",
    "\n",
    "\n",
    "                                    ''' Serialize via tfrecord '''\n",
    "                                    # Convert 3D data to 2D data\n",
    "                                    particle_pos_2D = np.zeros((frames+1, (r_particles+MODE_NUMBER)*dimension))\n",
    "                                    for i in range(frames+1):\n",
    "                                        for j in range(r_particles+MODE_NUMBER):\n",
    "                                            for k in range(dimension):\n",
    "                                                particle_pos_2D[i][dimension*j+k] = Xr[i][j][k]\n",
    "\n",
    "                                    particle_type_bytes = []\n",
    "                                    particle_pos_bytes = []\n",
    "                                    rigid_body_force_bytes = []\n",
    "\n",
    "                                    # ind = np.argmax(particles)\n",
    "                                    particle_type_bytes = struct.pack(\n",
    "                                            '%sq' % len(particle_type[0][:r_particles+MODE_NUMBER]), *particle_type[0][:r_particles+MODE_NUMBER])\n",
    "\n",
    "                                    for i in range(frames+1):\n",
    "                                        particle_pos_bytes.append(struct.pack(\n",
    "                                            '%sf' % len(particle_pos_2D[i]), *particle_pos_2D[i]))\n",
    "\n",
    "                                        rigid_body_force_bytes.append(struct.pack(\n",
    "                                            '%sf' % len(rigid_body_force[i]), *rigid_body_force[i]))\n",
    "\n",
    "                                    data = {\n",
    "                                        'context1': particle_type_bytes,\n",
    "                                        'context2': particle_key,\n",
    "                                        'feature1': particle_pos_bytes,\n",
    "                                        'feature2': rigid_body_force_bytes,\n",
    "                                    }\n",
    "                                    del particle_type\n",
    "                                    del particle_pos_2D\n",
    "                                    del particle_type_bytes\n",
    "                                    del particle_pos_bytes\n",
    "                                    del rigid_body_force_bytes\n",
    "                                    del particle_pos\n",
    "\n",
    "                                    example = tfrecord_excav.serialize(data)\n",
    "                                    writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "                                    ''' Calculate mean and variance '''\n",
    "                                    if split == 'train':\n",
    "                                        # # Calculate minimum particle distance to each particle => ~2cm => R=0.03m is the best\n",
    "                                        # for i in range(len(Xr[0])):\n",
    "                                        #     dist_i = 1000\n",
    "                                        #     for j in range(len(Xr[0])):\n",
    "                                        #         if i != j:\n",
    "                                        #             dist_j = np.linalg.norm(np.array(Xr[-1][j])-np.array(Xr[-1][i]))\n",
    "                                        #             if dist_j < dist_i:\n",
    "                                        #                 dist_i = dist_j\n",
    "                                        #     print(dist_i*100)\n",
    "\n",
    "                                        # Calculate particle velocities and accelerations\n",
    "                                        cc = 1\n",
    "                                        particle_vel = []\n",
    "                                        particle_acc = []\n",
    "                                        for frame in range(1, frames):\n",
    "                                            # Particle velocity (excluding rigid particles)\n",
    "                                            nparray1 = np.subtract(\n",
    "                                                np.array(Xr[frame][r_particles:]),\n",
    "                                                np.array(Xr[frame-1][r_particles:])) #* frame_rate\n",
    "                                            particle_vel.append(nparray1.tolist())\n",
    "                                            cc += 1\n",
    "                                            if frame >= 2:\n",
    "                                                # Particle acceleration (excluding rigid particles)\n",
    "                                                nparray2 = np.subtract(\n",
    "                                                    np.array(particle_vel[frame-1]),\n",
    "                                                    np.array(particle_vel[frame-2])) #* frame_rate\n",
    "                                                particle_acc.append(nparray2.tolist())\n",
    "                                            # Visualize velocity distribution\n",
    "                                            if VISUALIZATION:\n",
    "                                                xvel = []\n",
    "                                                yvel = []\n",
    "                                                zvel = []\n",
    "                                                xacc = []\n",
    "                                                yacc = []\n",
    "                                                zacc = []\n",
    "                                                if cc % 60 == 0:\n",
    "                                                    for i in range(len(particle_vel[-1])):\n",
    "                                                        xvel.append(particle_vel[-1][i][0])\n",
    "                                                        yvel.append(particle_vel[-1][i][1])\n",
    "                                                        zvel.append(particle_vel[-1][i][2])\n",
    "                                                        if i < len(particle_acc[-1]):\n",
    "                                                            xacc.append(particle_acc[-1][i][0])\n",
    "                                                            yacc.append(particle_acc[-1][i][1])\n",
    "                                                            zacc.append(particle_acc[-1][i][2])\n",
    "                                                    plt.figure(1)\n",
    "                                                    fig, axs = plt.subplots(3)\n",
    "                                                    fig.suptitle('Velocity histogram')\n",
    "                                                    axs[0].hist(xvel, bins=100, label='Vx')\n",
    "                                                    axs[0].legend(\"x\", loc=\"upper right\")\n",
    "                                                    axs[1].hist(yvel, bins=100, label='Vy')\n",
    "                                                    axs[1].legend(\"y\", loc=\"upper right\")\n",
    "                                                    axs[2].hist(zvel, bins=100, label='Vz')\n",
    "                                                    axs[2].legend(\"z\", loc=\"upper right\")\n",
    "                                                    plt.savefig(ds_path_save+'/vel_'+str(c1)+'_'+str(cc)+'.png', dpi=1000)\n",
    "                                                    plt.figure(2)\n",
    "                                                    fig, axs = plt.subplots(3)\n",
    "                                                    fig.suptitle('Acceleration histogram')\n",
    "                                                    axs[0].hist(xacc, bins=100, label='Vx')\n",
    "                                                    axs[0].legend(\"x\", loc=\"upper right\")\n",
    "                                                    axs[1].hist(yacc, bins=100, label='Vy')\n",
    "                                                    axs[1].legend(\"y\", loc=\"upper right\")\n",
    "                                                    axs[2].hist(zacc, bins=100, label='Vz')\n",
    "                                                    axs[2].legend(\"z\", loc=\"upper right\")\n",
    "                                                    plt.savefig(ds_path_save+'/acc_'+str(c1)+'_'+str(cc)+'.png', dpi=1000)\n",
    "\n",
    "                                        # Calculate mean and variance\n",
    "                                        xvel = []\n",
    "                                        yvel = []\n",
    "                                        zvel = []\n",
    "                                        xacc = []\n",
    "                                        yacc = []\n",
    "                                        zacc = []\n",
    "                                        for i in range(len(particle_vel)):\n",
    "                                            for j in range(len(particle_vel[-1])):\n",
    "                                                xvel.append(particle_vel[i][j][0])\n",
    "                                                yvel.append(particle_vel[i][j][1])\n",
    "                                                zvel.append(particle_vel[i][j][2])\n",
    "                                                if i < len(particle_acc) and j < len(particle_acc[-1]):\n",
    "                                                    xacc.append(particle_acc[i][j][0])\n",
    "                                                    yacc.append(particle_acc[i][j][1])\n",
    "                                                    zacc.append(particle_acc[i][j][2])\n",
    "                                        # Mean\n",
    "                                        particle_vel_mean_case = ([np.mean(xvel), np.mean(yvel), np.mean(zvel)])\n",
    "                                        particle_acc_mean_case = ([np.mean(xacc), np.mean(yacc), np.mean(zacc)])\n",
    "                                        rigid_body_force_mean_case = (np.mean(rigid_body_force, axis=0).tolist())\n",
    "                                        particle_vel_mean_old = particle_vel_mean\n",
    "                                        particle_acc_mean_old = particle_acc_mean\n",
    "                                        rigid_body_force_mean_old = rigid_body_force_mean\n",
    "                                        # Variance (Ref: https://www.emathzone.com/tutorials/basic-statistics/combined-variance.html)\n",
    "                                        particle_vel_var_case = ([np.var(xvel), np.var(yvel), np.var(zvel)])\n",
    "                                        particle_acc_var_case = ([np.var(xacc), np.var(yacc), np.var(zacc)])\n",
    "                                        rigid_body_force_var_case = (np.var(rigid_body_force, axis=0).tolist())\n",
    "                                        particle_vel_var_old = particle_vel_var\n",
    "                                        particle_acc_var_old = particle_acc_var\n",
    "                                        rigid_body_force_var_old = rigid_body_force_var\n",
    "                                        n1_v += n2_v\n",
    "                                        n2_v = len(xvel)\n",
    "                                        n1_a += n2_a\n",
    "                                        n2_a = len(xacc)\n",
    "                                        n1_f += n2_f\n",
    "                                        n2_f = len(rigid_body_force)\n",
    "                                        if particle_vel_mean[0] == 0:\n",
    "                                            particle_vel_mean = particle_vel_mean_case\n",
    "                                            particle_acc_mean = particle_acc_mean_case\n",
    "                                            rigid_body_force_mean = rigid_body_force_mean_case\n",
    "                                            particle_vel_var = particle_vel_var_case\n",
    "                                            particle_acc_var = particle_acc_var_case\n",
    "                                            rigid_body_force_var = rigid_body_force_var_case\n",
    "                                        else:\n",
    "                                            particle_vel_mean = np.divide(\n",
    "                                                np.add(np.multiply(particle_vel_mean_old, n1_v), np.multiply(particle_vel_mean_case, n2_v)), n1_v + n2_v)\n",
    "                                            particle_acc_mean = np.divide(\n",
    "                                                np.add(np.multiply(particle_acc_mean_old, n1_a), np.multiply(particle_acc_mean_case, n2_a)), n1_a + n2_a)\n",
    "                                            rigid_body_force_mean = np.divide(\n",
    "                                                np.add(np.multiply(rigid_body_force_mean_old, n1_f), np.multiply(rigid_body_force_mean_case, n2_f)), n1_f + n2_f)\n",
    "\n",
    "                                            if (n1_v + n2_v) > 0:\n",
    "                                                particle_vel_var = np.divide(np.add(\n",
    "                                                    np.multiply(n1_v, np.add(particle_vel_var_old, np.power(np.subtract(particle_vel_mean_old, particle_vel_mean), 2))),\n",
    "                                                    np.multiply(n2_v, np.add(particle_vel_var_case, np.power(np.subtract(particle_vel_mean_case, particle_vel_mean), 2)))),\n",
    "                                                    n1_v + n2_v)\n",
    "                                            if (n1_a + n2_a) > 0:\n",
    "                                                particle_acc_var = np.divide(np.add(\n",
    "                                                    np.multiply(n1_a, np.add(particle_acc_var_old, np.power(np.subtract(particle_acc_mean_old, particle_acc_mean), 2))),\n",
    "                                                    np.multiply(n2_a, np.add(particle_acc_var_case, np.power(np.subtract(particle_acc_mean_case, particle_acc_mean), 2)))),\n",
    "                                                    n1_a + n2_a)\n",
    "                                            rigid_body_force_var = np.divide(np.add(\n",
    "                                                np.multiply(n1_f, np.add(rigid_body_force_var_old, np.power(np.subtract(rigid_body_force_mean_old, rigid_body_force_mean), 2))),\n",
    "                                                np.multiply(n2_f, np.add(rigid_body_force_var_case, np.power(np.subtract(rigid_body_force_mean_case, rigid_body_force_mean), 2)))),\n",
    "                                                n1_f + n2_f)\n",
    "\n",
    "                                    c2 += 1\n",
    "                                    c3 += 1\n",
    "\n",
    "                                if c2 >= len_split:\n",
    "                                    break\n",
    "                            if c2 >= len_split:\n",
    "                                break\n",
    "                        if c2 >= len_split:\n",
    "                            break\n",
    "                    if c2 >= len_split:\n",
    "                        break\n",
    "\n",
    "\n",
    "        ''' Create metadata json file '''\n",
    "        if split == 'train':\n",
    "            print(\"Vel mean:\", np.array(particle_vel_mean).tolist())\n",
    "            print(\"Vel std:\", np.sqrt(particle_vel_var).tolist())\n",
    "            print(\"Acc mean:\", np.array(particle_acc_mean).tolist())\n",
    "            print(\"Acc std:\", np.sqrt(particle_acc_var).tolist())\n",
    "            print(\"Force mean:\", np.array(rigid_body_force_mean).tolist())\n",
    "            print(\"Force std:\", np.sqrt(rigid_body_force_var).tolist())\n",
    "            \n",
    "            rigid_body_ref_point = int(r_particles/2)\n",
    "\n",
    "            tfrecord_excav.write_json(\n",
    "                dataset_save,\n",
    "                bounds, frames, dimension, frame_rate,\n",
    "                np.array(particle_vel_mean).tolist(), np.sqrt(particle_vel_var).tolist(),\n",
    "                np.array(particle_acc_mean).tolist(), np.sqrt(particle_acc_var).tolist(),\n",
    "                np.array(rigid_body_force_mean).tolist(), np.sqrt(rigid_body_force_var).tolist(),\n",
    "                dataset_split,\n",
    "                rigid_body_ref_point, r_particles, MODE_NUMBER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10999feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
